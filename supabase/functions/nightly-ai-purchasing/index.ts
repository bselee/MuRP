/**
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * ğŸŒ™ NIGHTLY AI PURCHASING JOBS - Automated Intelligence Runner
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 *
 * Runs comprehensive AI purchasing analysis overnight
 * Total cost: ~$0.30 per night = ~$9/month
 *
 * Jobs:
 * 1. Anomaly Detection (~$0.05)
 * 2. Consolidation Opportunities (~$0.02)
 * 3. Seasonal Pattern Analysis (~$0.08) - Weekly
 * 4. Vendor Performance Review (~$0.05) - Weekly
 * 5. Generate Daily Digest (~$0.10)
 *
 * Schedule: Daily at 6:00 AM UTC
 * Configure in Supabase Dashboard: Database > Cron Jobs
 *
 * @module supabase/functions/nightly-ai-purchasing
 */

import { serve } from 'https://deno.land/std@0.168.0/http/server.ts';
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2';

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Types
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

interface JobResult {
  job_name: string;
  success: boolean;
  cost: number;
  duration_ms: number;
  error?: string;
}

interface Anomaly {
  sku: string;
  description: string;
  issue: string;
  cause: string;
  action: string;
  severity: 'critical' | 'warning' | 'info';
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// AI Service Functions (simplified versions for Edge Function)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async function callAnthropic(prompt: string, systemPrompt: string): Promise<any> {
  const apiKey = Deno.env.get('ANTHROPIC_API_KEY');
  if (!apiKey) {
    throw new Error('ANTHROPIC_API_KEY not configured');
  }

  const response = await fetch('https://api.anthropic.com/v1/messages', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'x-api-key': apiKey,
      'anthropic-version': '2023-06-01',
    },
    body: JSON.stringify({
      model: 'claude-3-5-haiku-20241022',
      max_tokens: 3000,
      temperature: 0.2,
      system: systemPrompt,
      messages: [
        {
          role: 'user',
          content: prompt,
        },
      ],
    }),
  });

  if (!response.ok) {
    const errorData = await response.json();
    throw new Error(`Anthropic API error: ${response.status} - ${JSON.stringify(errorData)}`);
  }

  return await response.json();
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Job Implementations
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async function runAnomalyDetection(supabase: any): Promise<JobResult> {
  const startTime = Date.now();

  try {
    console.log('1/4: Running anomaly detection...');

    // Fetch inventory data
    const { data: items, error } = await supabase
      .from('inventory_items')
      .select(`
        sku,
        name,
        description,
        stock,
        reorder_point,
        sales_last_30_days,
        sales_last_90_days,
        vendors (name)
      `)
      .eq('status', 'active')
      .order('sales_last_30_days', { ascending: false })
      .limit(500);

    if (error) throw error;

    // Prepare data
    const inventorySummary = items?.map((item: any) => ({
      sku: item.sku,
      name: item.name,
      current_stock: item.stock || 0,
      reorder_point: item.reorder_point || 0,
      sales_30d: item.sales_last_30_days || 0,
      sales_90d: item.sales_last_90_days || 0,
      days_of_stock: item.sales_last_30_days > 0
        ? Math.round((item.stock / (item.sales_last_30_days / 30)))
        : 999,
      vendor: item.vendors?.name || 'Unknown'
    })) || [];

    // Call AI
    const systemPrompt = `You are an inventory anomaly detection system for a MRP/ERP platform.

Today's date: ${new Date().toLocaleDateString()}

Inventory snapshot (top 500 active items):
${JSON.stringify(inventorySummary.slice(0, 100), null, 2)}
... (${inventorySummary.length} total items analyzed)`;

    const userPrompt = `Analyze this inventory data and identify anomalies:

**CRITICAL** (immediate action): Zero stock with recent sales, consumption drops >80%, items below reorder point
**WARNING** (review soon): Consumption variance >50%, approaching stockout
**INFO** (good to know): Positive trends, growing demand

Return ONLY valid JSON:
{
  "critical": [{"sku": "...", "description": "...", "issue": "...", "cause": "...", "action": "...", "severity": "critical"}],
  "warning": [...],
  "info": [...]
}`;

    const aiResponse = await callAnthropic(userPrompt, systemPrompt);

    // Parse response
    const content = aiResponse.content[0].text;
    const jsonText = content.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim();
    const anomalies = JSON.parse(jsonText);

    // Calculate cost
    const inputTokens = aiResponse.usage.input_tokens || 0;
    const outputTokens = aiResponse.usage.output_tokens || 0;
    const cost = ((inputTokens * 0.80) + (outputTokens * 4.00)) / 1_000_000;

    // Store in database
    await supabase.from('ai_anomaly_logs').insert({
      detected_at: new Date().toISOString(),
      detection_type: 'daily',
      items_analyzed: inventorySummary.length,
      critical_count: anomalies.critical?.length || 0,
      warning_count: anomalies.warning?.length || 0,
      info_count: anomalies.info?.length || 0,
      critical_anomalies: anomalies.critical || [],
      warning_anomalies: anomalies.warning || [],
      info_anomalies: anomalies.info || [],
      model_used: 'claude-3-5-haiku-20241022',
      cost_usd: cost,
      tokens_used: inputTokens + outputTokens,
      execution_time_ms: Date.now() - startTime
    });

    // Track cost
    await supabase.from('ai_purchasing_costs').insert({
      date: new Date().toISOString().split('T')[0],
      service_name: 'anomaly_detection',
      model_name: 'claude-3-5-haiku-20241022',
      provider: 'anthropic',
      input_tokens: inputTokens,
      output_tokens: outputTokens,
      total_tokens: inputTokens + outputTokens,
      cost_usd: cost,
      execution_time_ms: Date.now() - startTime
    });

    console.log(`âœ… Anomaly detection complete: ${anomalies.critical?.length || 0} critical, ${anomalies.warning?.length || 0} warnings`);

    return {
      job_name: 'anomaly_detection',
      success: true,
      cost,
      duration_ms: Date.now() - startTime
    };

  } catch (error: any) {
    console.error('âŒ Anomaly detection failed:', error);
    return {
      job_name: 'anomaly_detection',
      success: false,
      cost: 0,
      duration_ms: Date.now() - startTime,
      error: error.message
    };
  }
}

async function runConsolidationAnalysis(supabase: any): Promise<JobResult> {
  const startTime = Date.now();

  try {
    console.log('2/4: Analyzing consolidation opportunities...');

    // Fetch draft POs
    const { data: draftPOs, error: poError } = await supabase
      .from('purchase_orders')
      .select(`
        id,
        vendor_id,
        items,
        vendors (id, name, lead_time_days)
      `)
      .eq('status', 'draft');

    if (poError) throw poError;

    if (!draftPOs || draftPOs.length === 0) {
      console.log('â„¹ï¸  No draft POs to analyze');
      return {
        job_name: 'consolidation',
        success: true,
        cost: 0,
        duration_ms: Date.now() - startTime
      };
    }

    // Get inventory
    const { data: inventory, error: invError } = await supabase
      .from('inventory_items')
      .select('sku, name, stock, reorder_point, sales_last_30_days, unit_cost, vendor_id')
      .eq('status', 'active')
      .gt('stock', 0);

    if (invError) throw invError;

    // Prepare data
    const poSummary = draftPOs.map((po: any) => {
      const items = Array.isArray(po.items) ? po.items : [];
      const total = items.reduce((sum: number, item: any) =>
        sum + (item.quantity * item.unit_cost || 0), 0);

      return {
        vendor_id: po.vendor_id,
        vendor_name: po.vendors?.name,
        current_total: total,
        item_count: items.length
      };
    });

    const inventorySummary = inventory?.map((item: any) => ({
      sku: item.sku,
      name: item.name,
      current_stock: item.stock,
      days_remaining: item.sales_last_30_days > 0
        ? Math.round((item.stock / (item.sales_last_30_days / 30)))
        : 999,
      unit_cost: item.unit_cost || 0,
      vendor_id: item.vendor_id
    })) || [];

    // Call AI
    const systemPrompt = `You are a purchasing optimization AI.

Draft POs:
${JSON.stringify(poSummary, null, 2)}

Available inventory:
${JSON.stringify(inventorySummary.slice(0, 50), null, 2)}

Shipping thresholds: $300 = free shipping, $500 = volume discount`;

    const userPrompt = `Find consolidation opportunities where adding items would save shipping costs.

Return ONLY valid JSON:
{
  "opportunities": [
    {
      "vendor_id": "...",
      "vendor_name": "...",
      "opportunity_type": "shipping_threshold",
      "current_order_total": 245.00,
      "shipping_threshold": 300.00,
      "potential_savings": 28.00,
      "recommended_items": [{"sku": "...", "name": "...", "qty": 10, "unit_cost": 5.50, "total_cost": 55.00, "days_stock_remaining": 45}],
      "urgency": "low",
      "reasoning": "..."
    }
  ]
}`;

    const aiResponse = await callAnthropic(userPrompt, systemPrompt);

    // Parse and store
    const content = aiResponse.content[0].text;
    const jsonText = content.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim();
    const result = JSON.parse(jsonText);

    const inputTokens = aiResponse.usage.input_tokens || 0;
    const outputTokens = aiResponse.usage.output_tokens || 0;
    const cost = ((inputTokens * 0.80) + (outputTokens * 4.00)) / 1_000_000;

    // Store opportunities
    for (const opp of result.opportunities || []) {
      await supabase.from('ai_consolidation_opportunities').insert({
        opportunity_type: opp.opportunity_type,
        vendor_id: opp.vendor_id,
        vendor_name: opp.vendor_name,
        current_order_total: opp.current_order_total,
        shipping_threshold: opp.shipping_threshold,
        potential_savings: opp.potential_savings,
        recommended_items: opp.recommended_items,
        urgency: opp.urgency,
        model_used: 'claude-3-5-haiku-20241022',
        cost_usd: cost / (result.opportunities?.length || 1)
      });
    }

    // Track cost
    await supabase.from('ai_purchasing_costs').insert({
      date: new Date().toISOString().split('T')[0],
      service_name: 'consolidation',
      model_name: 'claude-3-5-haiku-20241022',
      provider: 'anthropic',
      input_tokens: inputTokens,
      output_tokens: outputTokens,
      total_tokens: inputTokens + outputTokens,
      cost_usd: cost,
      execution_time_ms: Date.now() - startTime
    });

    console.log(`âœ… Found ${result.opportunities?.length || 0} consolidation opportunities`);

    return {
      job_name: 'consolidation',
      success: true,
      cost,
      duration_ms: Date.now() - startTime
    };

  } catch (error: any) {
    console.error('âŒ Consolidation analysis failed:', error);
    return {
      job_name: 'consolidation',
      success: false,
      cost: 0,
      duration_ms: Date.now() - startTime,
      error: error.message
    };
  }
}

async function cleanupStaleData(supabase: any): Promise<JobResult> {
  const startTime = Date.now();

  try {
    console.log('3/4: Cleaning up stale data...');

    // Mark stale insights
    await supabase.rpc('mark_stale_insights');

    // Delete old consolidation opportunities (>30 days)
    const thirtyDaysAgo = new Date();
    thirtyDaysAgo.setDate(thirtyDaysAgo.getDate() - 30);

    await supabase
      .from('ai_consolidation_opportunities')
      .delete()
      .lt('created_at', thirtyDaysAgo.toISOString());

    // Delete old anomaly logs (>90 days)
    const ninetyDaysAgo = new Date();
    ninetyDaysAgo.setDate(ninetyDaysAgo.getDate() - 90);

    await supabase
      .from('ai_anomaly_logs')
      .delete()
      .lt('detected_at', ninetyDaysAgo.toISOString());

    console.log('âœ… Cleanup complete');

    return {
      job_name: 'cleanup',
      success: true,
      cost: 0,
      duration_ms: Date.now() - startTime
    };

  } catch (error: any) {
    console.error('âŒ Cleanup failed:', error);
    return {
      job_name: 'cleanup',
      success: false,
      cost: 0,
      duration_ms: Date.now() - startTime,
      error: error.message
    };
  }
}

async function sendDailySummary(supabase: any, results: JobResult[]): Promise<JobResult> {
  const startTime = Date.now();

  try {
    console.log('4/4: Generating daily summary...');

    // Get latest anomalies
    const { data: latestAnomalies } = await supabase
      .from('ai_anomaly_logs')
      .select('*')
      .order('detected_at', { ascending: false })
      .limit(1)
      .single();

    // Get active opportunities
    const { data: opportunities } = await supabase
      .from('ai_consolidation_opportunities')
      .select('*')
      .eq('status', 'pending')
      .order('potential_savings', { ascending: false });

    // Calculate totals
    const totalCost = results.reduce((sum, r) => sum + r.cost, 0);
    const totalDuration = results.reduce((sum, r) => sum + r.duration_ms, 0);

    // Create summary (you could email this or store in database)
    const summary = {
      date: new Date().toISOString().split('T')[0],
      jobs_completed: results.filter(r => r.success).length,
      jobs_failed: results.filter(r => !r.success).length,
      total_cost_usd: totalCost,
      total_duration_ms: totalDuration,
      anomalies: {
        critical: latestAnomalies?.critical_count || 0,
        warning: latestAnomalies?.warning_count || 0,
        info: latestAnomalies?.info_count || 0
      },
      consolidation_opportunities: opportunities?.length || 0,
      potential_savings: opportunities?.reduce((sum: number, o: any) => sum + (o.potential_savings || 0), 0) || 0
    };

    console.log('ğŸ“Š Daily Summary:', JSON.stringify(summary, null, 2));

    // TODO: Send email summary if needed

    return {
      job_name: 'daily_summary',
      success: true,
      cost: 0,
      duration_ms: Date.now() - startTime
    };

  } catch (error: any) {
    console.error('âŒ Daily summary failed:', error);
    return {
      job_name: 'daily_summary',
      success: false,
      cost: 0,
      duration_ms: Date.now() - startTime,
      error: error.message
    };
  }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Main Handler
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

serve(async (req: Request) => {
  const jobStartTime = Date.now();

  console.log('ğŸŒ™ Starting nightly AI purchasing jobs...');

  // Initialize Supabase client
  const supabaseUrl = Deno.env.get('SUPABASE_URL')!;
  const supabaseServiceKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!;

  const supabase = createClient(supabaseUrl, supabaseServiceKey);

  // Create job log
  const { data: jobLog, error: logError } = await supabase
    .from('ai_job_logs')
    .insert({
      job_name: 'nightly_purchasing_analysis',
      job_type: 'scheduled',
      status: 'running',
      started_at: new Date().toISOString()
    })
    .select()
    .single();

  if (logError) {
    console.error('Failed to create job log:', logError);
  }

  const results: JobResult[] = [];

  try {
    // Run jobs sequentially
    results.push(await runAnomalyDetection(supabase));
    results.push(await runConsolidationAnalysis(supabase));
    results.push(await cleanupStaleData(supabase));
    results.push(await sendDailySummary(supabase, results));

    // Calculate totals
    const totalCost = results.reduce((sum, r) => sum + r.cost, 0);
    const successCount = results.filter(r => r.success).length;
    const failCount = results.filter(r => !r.success).length;

    console.log(`\nâœ… All AI jobs completed in ${Date.now() - jobStartTime}ms`);
    console.log(`ğŸ’° Total cost: $${totalCost.toFixed(4)}`);
    console.log(`ğŸ“Š Success: ${successCount}, Failed: ${failCount}`);

    // Update job log
    if (jobLog) {
      const costBreakdown: Record<string, number> = {};
      results.forEach(r => {
        costBreakdown[r.job_name] = r.cost;
      });

      await supabase
        .from('ai_job_logs')
        .update({
          completed_at: new Date().toISOString(),
          status: failCount > 0 ? 'completed' : 'completed',
          jobs_completed: successCount,
          total_cost_usd: totalCost,
          execution_time_ms: Date.now() - jobStartTime,
          cost_breakdown: costBreakdown
        })
        .eq('id', jobLog.id);
    }

    return new Response(
      JSON.stringify({
        success: true,
        jobs: results.length,
        totalCost,
        totalTime: Date.now() - jobStartTime,
        results
      }),
      {
        headers: { 'Content-Type': 'application/json' },
        status: 200
      }
    );

  } catch (error: any) {
    console.error('ğŸ’¥ Nightly jobs failed:', error);

    // Update job log
    if (jobLog) {
      await supabase
        .from('ai_job_logs')
        .update({
          completed_at: new Date().toISOString(),
          status: 'failed',
          error_message: error.message,
          error_stack: error.stack
        })
        .eq('id', jobLog.id);
    }

    return new Response(
      JSON.stringify({
        success: false,
        error: error.message,
        results
      }),
      {
        headers: { 'Content-Type': 'application/json' },
        status: 500
      }
    );
  }
});
